{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time as time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chunk:\n",
    "    def __init__(self, X,Y=None):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "        if self.Y == None:\n",
    "            self.Y = self.X\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def sim_matrix(self, a, b, eps=1e-8):\n",
    "        \"\"\"\n",
    "        Compute the cosine similarity between two matrices of vectors\n",
    "        :param a: matrix of vectors (n x d)\n",
    "        :param b: matrix of vectors (m x d)\n",
    "        :param eps: added eps for numerical stability\n",
    "        :return: scalar product between each vector of a and each vector of b (n x m)\n",
    "        \"\"\"\n",
    "        a_n, b_n = a.norm(dim=1)[:, None], b.norm(dim=1)[:, None]\n",
    "        a_norm = a / torch.clamp(a_n, min=eps)\n",
    "        b_norm = b / torch.clamp(b_n, min=eps)\n",
    "        sim_mt = torch.mm(a_norm, b_norm.transpose(0, 1))\n",
    "        return sim_mt\n",
    "    \n",
    "    def compute_sim_matrix(self, keep_n=10, chunk_size=100, verbose=True):\n",
    "        \"\"\"\n",
    "        Compute the similarity matrix between X and Y and return the indices of the top-n elements as well as the distances\n",
    "        Args:\n",
    "        keep_n: number of elements to keep\n",
    "        chunk_size: size of the chunks to split the data. This is useful to avoid memory issues\n",
    "        \"\"\"\n",
    "        assert keep_n <= chunk_size, \"keep_n should be less than or equal to chunk_size\"\n",
    "        assert keep_n <= self.Y.shape[0], \"keep_n should be less or equal to the number of elements in Y\"\n",
    "        if self.device == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "        indices = torch.zeros(self.X.shape[0], keep_n)\n",
    "        distances = torch.zeros(self.X.shape[0], keep_n)\n",
    "\n",
    "        splits_X = self.X.split(chunk_size,dim=0)\n",
    "        split_lenght_X = [i.shape[0] for i in splits_X]\n",
    "\n",
    "        splits_Y = self.Y.split(chunk_size,dim=0)\n",
    "        split_lenghts_Y = [i.shape[0] for i in splits_Y]\n",
    "\n",
    "        print(f\"Number of chunks for X: {len(splits_X)}\")\n",
    "        print(f\"Number of chunks for Y: {len(splits_Y)}\")\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        for k,i in enumerate(splits_X):\n",
    "            top_n_all_fused = []\n",
    "            top_n_all_fused_values = []\n",
    "            y_dim = i.shape[0]\n",
    "            for l,j in enumerate(splits_Y):\n",
    "                if self.device == \"cuda\":\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        inter = self.sim_matrix(i.to(self.device),j.to(self.device))\n",
    "                        inter, top_n = torch.topk(inter, k=keep_n, dim=1)\n",
    "                        top_n_all_fused_values.append(inter)\n",
    "                        top_n_all_fused.append(top_n+sum(split_lenghts_Y[:l]))\n",
    "                else:\n",
    "                    inter = self.sim_matrix(i,j)\n",
    "                    inter, top_n = torch.topk(inter, k=keep_n, dim=1)\n",
    "                    top_n_all_fused_values.append(inter)\n",
    "                    top_n_all_fused.append(top_n+sum(split_lenghts_Y[:l]))\n",
    "\n",
    "                if verbose == True:\n",
    "                    print(f\"Processing of chunk {k+1}/{len(splits_X)} with chunk {l+1}/{len(splits_Y)} done in {time.time()-start:2.3f}s\")\n",
    "\n",
    "            top_n_all_fused = torch.cat(top_n_all_fused,dim=1)\n",
    "            top_n_all_fused_values = torch.cat(top_n_all_fused_values,dim=1)\n",
    "\n",
    "            if self.device == \"cuda\":    \n",
    "                with torch.cuda.amp.autocast():\n",
    "                    val, top_n_all_fused_values = torch.topk(top_n_all_fused_values,k=keep_n,dim=1)\n",
    "            else:\n",
    "                val, top_n_all_fused_values = torch.topk(top_n_all_fused_values,k=keep_n,dim=1)\n",
    "\n",
    "            comb = torch.cat([a[i].reshape(1,-1) for a,i in zip(top_n_all_fused,top_n_all_fused_values)],dim=0)\n",
    "\n",
    "            indices[sum(split_lenght_X[:k]):sum(split_lenght_X[:k])+y_dim] = comb.cpu()\n",
    "            distances[sum(split_lenght_X[:k]):sum(split_lenght_X[:k])+y_dim] = val.cpu()\n",
    "\n",
    "            del val, comb, top_n_all_fused, top_n_all_fused_values, inter, top_n\n",
    "            if self.device == \"cuda\":\n",
    "                torch.cuda.empty_cache()\n",
    "        return indices, distances\n",
    "    \n",
    "    def get_chunk_size(self):\n",
    "        pass\n",
    "\n",
    "    def verbose(self, *args):\n",
    "        pass\n",
    "        \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks for X: 5\n",
      "Number of chunks for Y: 10\n",
      "Processing of chunk 1/5 with chunk 1/10 done in 0.006s\n",
      "Processing of chunk 1/5 with chunk 2/10 done in 0.011s\n",
      "Processing of chunk 1/5 with chunk 3/10 done in 0.016s\n",
      "Processing of chunk 1/5 with chunk 4/10 done in 0.020s\n",
      "Processing of chunk 1/5 with chunk 5/10 done in 0.025s\n",
      "Processing of chunk 1/5 with chunk 6/10 done in 0.028s\n",
      "Processing of chunk 1/5 with chunk 7/10 done in 0.032s\n",
      "Processing of chunk 1/5 with chunk 8/10 done in 0.036s\n",
      "Processing of chunk 1/5 with chunk 9/10 done in 0.040s\n",
      "Processing of chunk 1/5 with chunk 10/10 done in 0.043s\n",
      "Processing of chunk 2/5 with chunk 1/10 done in 0.058s\n",
      "Processing of chunk 2/5 with chunk 2/10 done in 0.062s\n",
      "Processing of chunk 2/5 with chunk 3/10 done in 0.065s\n",
      "Processing of chunk 2/5 with chunk 4/10 done in 0.068s\n",
      "Processing of chunk 2/5 with chunk 5/10 done in 0.071s\n",
      "Processing of chunk 2/5 with chunk 6/10 done in 0.074s\n",
      "Processing of chunk 2/5 with chunk 7/10 done in 0.078s\n",
      "Processing of chunk 2/5 with chunk 8/10 done in 0.081s\n",
      "Processing of chunk 2/5 with chunk 9/10 done in 0.085s\n",
      "Processing of chunk 2/5 with chunk 10/10 done in 0.089s\n",
      "Processing of chunk 3/5 with chunk 1/10 done in 0.103s\n",
      "Processing of chunk 3/5 with chunk 2/10 done in 0.107s\n",
      "Processing of chunk 3/5 with chunk 3/10 done in 0.110s\n",
      "Processing of chunk 3/5 with chunk 4/10 done in 0.113s\n",
      "Processing of chunk 3/5 with chunk 5/10 done in 0.117s\n",
      "Processing of chunk 3/5 with chunk 6/10 done in 0.120s\n",
      "Processing of chunk 3/5 with chunk 7/10 done in 0.124s\n",
      "Processing of chunk 3/5 with chunk 8/10 done in 0.127s\n",
      "Processing of chunk 3/5 with chunk 9/10 done in 0.130s\n",
      "Processing of chunk 3/5 with chunk 10/10 done in 0.134s\n",
      "Processing of chunk 4/5 with chunk 1/10 done in 0.149s\n",
      "Processing of chunk 4/5 with chunk 2/10 done in 0.152s\n",
      "Processing of chunk 4/5 with chunk 3/10 done in 0.156s\n",
      "Processing of chunk 4/5 with chunk 4/10 done in 0.159s\n",
      "Processing of chunk 4/5 with chunk 5/10 done in 0.162s\n",
      "Processing of chunk 4/5 with chunk 6/10 done in 0.167s\n",
      "Processing of chunk 4/5 with chunk 7/10 done in 0.170s\n",
      "Processing of chunk 4/5 with chunk 8/10 done in 0.173s\n",
      "Processing of chunk 4/5 with chunk 9/10 done in 0.176s\n",
      "Processing of chunk 4/5 with chunk 10/10 done in 0.179s\n",
      "Processing of chunk 5/5 with chunk 1/10 done in 0.195s\n",
      "Processing of chunk 5/5 with chunk 2/10 done in 0.199s\n",
      "Processing of chunk 5/5 with chunk 3/10 done in 0.203s\n",
      "Processing of chunk 5/5 with chunk 4/10 done in 0.206s\n",
      "Processing of chunk 5/5 with chunk 5/10 done in 0.209s\n",
      "Processing of chunk 5/5 with chunk 6/10 done in 0.212s\n",
      "Processing of chunk 5/5 with chunk 7/10 done in 0.216s\n",
      "Processing of chunk 5/5 with chunk 8/10 done in 0.220s\n",
      "Processing of chunk 5/5 with chunk 9/10 done in 0.224s\n",
      "Processing of chunk 5/5 with chunk 10/10 done in 0.227s\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(5000,32)\n",
    "b = torch.randn(10000,32)\n",
    "c = Chunk(a,b)\n",
    "k = c.compute_sim_matrix(keep_n=30, chunk_size=1000, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0000e+00, 2.4620e+03, 3.4170e+03,  ..., 2.9430e+03, 2.3330e+03,\n",
       "          4.9170e+03],\n",
       "         [1.0000e+00, 2.5680e+03, 2.3110e+03,  ..., 3.7400e+03, 3.6840e+03,\n",
       "          3.1560e+03],\n",
       "         [2.0000e+00, 2.7620e+03, 3.3780e+03,  ..., 1.7100e+02, 4.9770e+03,\n",
       "          3.7700e+02],\n",
       "         ...,\n",
       "         [4.9970e+03, 1.7640e+03, 5.3100e+02,  ..., 1.8880e+03, 1.5390e+03,\n",
       "          8.3300e+02],\n",
       "         [4.9980e+03, 3.3560e+03, 2.7890e+03,  ..., 4.4920e+03, 3.2230e+03,\n",
       "          3.3140e+03],\n",
       "         [4.9990e+03, 6.3400e+02, 3.4480e+03,  ..., 2.2960e+03, 2.9650e+03,\n",
       "          1.9400e+02]]),\n",
       " tensor([[1.0000, 0.5896, 0.5683,  ..., 0.4407, 0.4396, 0.4383],\n",
       "         [1.0000, 0.7273, 0.5525,  ..., 0.4221, 0.4193, 0.4191],\n",
       "         [1.0000, 0.5572, 0.5523,  ..., 0.4383, 0.4376, 0.4369],\n",
       "         ...,\n",
       "         [1.0000, 0.5746, 0.5151,  ..., 0.4330, 0.4310, 0.4292],\n",
       "         [1.0000, 0.6351, 0.6035,  ..., 0.4323, 0.4293, 0.4280],\n",
       "         [1.0000, 0.5834, 0.5682,  ..., 0.4276, 0.4257, 0.4247]]))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4237,  0.4108,  0.3189,  0.1641,  0.0533, -0.0518, -0.1069, -0.1566,\n",
       "         -0.1658, -0.1773],\n",
       "        [ 0.2841,  0.1914, -0.0286, -0.0307, -0.0742, -0.0869, -0.0958, -0.2334,\n",
       "         -0.3007, -0.4513],\n",
       "        [ 0.2100,  0.1110,  0.0564,  0.0510, -0.0655, -0.1925, -0.2202, -0.2214,\n",
       "         -0.2465, -0.2558],\n",
       "        [ 0.2392,  0.1191,  0.0660, -0.0197, -0.0996, -0.1177, -0.1702, -0.1759,\n",
       "         -0.3280, -0.3513],\n",
       "        [ 0.1260,  0.0768,  0.0401, -0.0016, -0.0432, -0.0542, -0.1386, -0.1932,\n",
       "         -0.2641, -0.4437],\n",
       "        [ 0.2901,  0.1198, -0.0116, -0.0966, -0.1017, -0.2160, -0.2720, -0.2991,\n",
       "         -0.3387, -0.3425],\n",
       "        [ 0.2860,  0.2406,  0.1618,  0.0637,  0.0618, -0.0146, -0.0677, -0.1033,\n",
       "         -0.1410, -0.1941],\n",
       "        [ 0.3961,  0.2570,  0.1627,  0.0603, -0.0013, -0.0378, -0.0475, -0.0796,\n",
       "         -0.1045, -0.1971],\n",
       "        [ 0.4101,  0.0323,  0.0321,  0.0282,  0.0243, -0.1340, -0.1390, -0.1404,\n",
       "         -0.1476, -0.1952],\n",
       "        [ 0.0783,  0.0563,  0.0404, -0.0267, -0.0279, -0.1507, -0.1523, -0.1632,\n",
       "         -0.1897, -0.2799]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
